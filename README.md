[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) [![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
# Awesome Audio-Visual Embodied Navigation

#### A continuously updated project to track the latest progress in Audio-Visual Embodied Navigation (AVEN).
#### If this repository can bring you some inspiration, we would feel greatly honored.
#### If you like our project, please give us a star ⭐ on this GitHub.
#### We welcome researchers to submit pull requests and become contributors to this project.

## :fire: Highlights
![Last Updated](https://badgen.net/github/last-commit/983632847/Awesome-Audio-Visual-Navigation?icon=github&label=last%20updated&color=green)
- 2025.08.29: Awesome Audio-Visual Embodied Navigation Project Started.


## Table of Content
* [Datasets](#datasets)
* [Papers](#papers)



## <a name="datasets"></a> Datasets
| Dataset | Pub. & Date  | WebSite | Introduction |
|:-----:|:-----:|:-----:|:-----:|
| [Replica](https://arxiv.org/abs/1912.11474)   |  ECCV-2020  |  [Replica](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)  |  18 Scenes, discrete grid (0.5m)  |  
| [Matterport3D](https://arxiv.org/abs/1912.11474)   |  ECCV-2020  |  [Matterport3D](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)  |  85 Scenes, discrete grid (1m) |  


## <a name="papers"></a> Papers
#### 2020
- **SoundSpaces:** Changan Chen*, Unnat Jain*, Carl Schissler, Sebastia Vicenc Amengual Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, Kristen Grauman.<br />
  "SoundSpaces: Audio-Visual Navigation in 3D Environments." ECCV (2020).
  [[paper](https://arxiv.org/abs/1912.11474)] 
  [[website]](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)

- **VAR:** Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong, Joshua B. Tenenbaum.<br />
  "Look, Listen, and Act: Towards Audio-Visual Embodied Navigation." ICRA (2020).
  [[paper](https://arxiv.org/abs/1912.11684)] 
  [[website](http://avn.csail.mit.edu/)]

#### 2021
- **AV-WaN:** Changan Chen, Sagnik Majumder, Ziad Al-Halah, Ruohan Gao, Santhosh K. Ramakrishnan, Kristen Grauman.<br />
  "Learning to Set Waypoints for Audio-Visual Navigation." ICLR (2021).
  [[paper](https://arxiv.org/pdf/2008.09622.pdf)] 
  [[website](http://vision.cs.utexas.edu/projects/audio_visual_waypoints/)]

- **SAVi:** Changan Chen, Ziad Al-Halah, Kristen Grauman.<br />
  "Semantic Audio-Visual Navigation." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2012.11583)] 
  [[code](https://github.com/facebookresearch/sound-spaces/tree/main/ss_baselines/savi)]
  [[website](http://vision.cs.utexas.edu/projects/semantic-audio-visual-navigation)]

- **Move2Hear:** Move2Hear: Active Audio-Visual Source Separation.<br />
  "Move2Hear: Active Audio-Visual Source Separation." ICCV (2021).
  [[paper](https://arxiv.org/abs/2105.07142)] 
  [[website](http://vision.cs.utexas.edu/projects/move2hear/)]


#### 2022
- **AAVS:** Sagnik Majumder, Ziad Al-Halah, and Kristen Grauman.<br />
  "Active Audio-Visual Separation of Dynamic Sound Sources." ECCV (2025).
  [[paper](https://arxiv.org/abs/2202.00850)] 
  [[code](https://github.com/SAGNIKMJR/active-av-dynamic-separation)]
[[website](https://vision.cs.utexas.edu/projects/active-av-dynamic-separation/)]

- **SAAVN:** Yinfeng Yu, Wenbing Huang, Fuchun Sun, Changan Chen, Yikai Wang, Xiaohong Liu.<br />
  "Sound Adversarial Audio-Visual Navigation." ICLR (2022).
  [[paper](https://openreview.net/pdf?id=NkZq4OEYN-)] 
  [[code](https://github.com/yyf17/SAAVN/tree/main)]
  [[website](https://yyf17.github.io/SAAVN)]

- **SoundSpaces 2.0:** Changan Chen*, Carl Schissler*, Sanchit Garg*, Philip Kobernik, Alexander Clegg, Paul Calamia, Dhruv Batra, Philip W Robinson, Kristen Grauman.<br />
  "SoundSpaces 2.0: A Simulation Platform for Visual-Acoustic Learning." NeurIPS (2022).
[[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/3a48b0eaba26ba862220a307a9edb0bb-Paper-Datasets_and_Benchmarks.pdf)] 
  [[code](https://github.com/facebookresearch/sound-spaces)]
  [[website](https://vision.cs.utexas.edu/projects/soundspaces2)]

- **AVLEN:** Sudipta Paul, Amit K. Roy-Chowdhury, Anoop Cherian.<br />
  "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2210.07940)] 

- **FSAAVN:** Yinfeng Yu, Lele Cao, Fuchun Sun, Xiaohong Liu, Liejun Wang.<br />
  "Pay Self-Attention to Audio-Visual Navigation." BMVC (2022).
  [[paper](https://arxiv.org/pdf/2210.01353.pdf)] 
  [[website](https://yyf17.github.io/FSAAVN/index.html)]

- **Dav-Nav:** Abdelrahman Younes, Daniel Honerkamp, Tim Welschehold, Abhinav Valada.<br />
  "Catch Me If You Hear Me: Audio-Visual Navigation in Complex Unmapped Environments with Moving Sounds." IEEE RA-L (2022).
  [[paper](https://arxiv.org/abs/2111.14843)]
  [[code](https://github.com/robot-learning-freiburg/Dav-Nav)]
  [[website](http://dav-nav.cs.uni-freiburg.de/)]
  
- **K-SAVEN:** Gyan Tatiya, Jonathan Francis, Luca Bondi, Ingrid Navarro, Eric Nyberg, Jivko Sinapov, Jean Oh.<br />
  "Knowledge-driven Scene Priors for Semantic Audio-Visual Embodied Navigation." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2212.11345)] 

#### 2023
- **SA2GVAN:** Hongcheng Wang*, Yuxuan Wang*, Fangwei Zhong, Mingdong Wu, Jianwei Zhang, Yizhou Wang, Hao Dong*.<br />
  "Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation." IEEE RA-L (2023).
  [[paper](https://arxiv.org/pdf/2304.10773.pdf)] 
  [[code](https://github.com/wwwwwyyyyyxxxxx/SA2GVAN)]
  [[website](https://sites.google.com/view/sasavan/)]

- **ORAN:** Jinyu Chen, Wenguan Wang, Si Liu, Hongsheng Li, Yi Yang.<br />
  "Omnidirectional Information Gathering for Knowledge Transfer-based Audio-Visual Navigation." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/chenjinyubuaa/ORAN)]

#### 2024
- **RILA:** Yang, Zeyuan and Lin, Jiageng and Chen, Peihao and Cherian, Anoop and Marks, Tim K. and Roux, Jonathan Le and Gan, Chuang.<br />
  "RILA: Reflective and Imaginative Language Agent for Zero-Shot Semantic
Audio-Visual Navigation." CVPR (2024).
 [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_RILA_Reflective_and_Imaginative_Language_Agent_for_Zero-Shot_Semantic_Audio-Visual_CVPR_2024_paper.pdf)] 
  [[website](https://rila-savn.github.io/RILA)]

- **CAVEN:** Xiulong Liu, Sudipta Paul, Moitreya Chatterjee, Anoop Cherian.<br />
  "CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments." AAAI (2024).
  [[paper](https://arxiv.org/abs/2306.04047)] 

- **AFP:** Changan Chen*, Jordi Ramos*, Anshul Tomar*, Kristen Grauman.<br />
  "Sim2Real Transfer for Audio-Visual Navigation with Frequency-Adaptive Acoustic Field Prediction." IROS (2024).
  [[paper](https://arxiv.org/pdf/2405.02821)] 
  [[website](https://vision.cs.utexas.edu/projects/sim2real/)]
  
#### 2025
- **FAVEN:** Shentong Mo, Shentong_Mo, Kilian Q Weinberger, Marco Pavone, Boyi Li.<br />
  "FAVEN: Fast Audio-Visual Embodied Navigation in 3D Environments." ArXiv (2025).
  [[paper](https://openreview.net/forum?id=48nAxwEyQ0)]


## Awesome Repositories for Embodied AI
- [Awesome Embodied Vision](https://github.com/ChanganVR/awesome-embodied-vision)
- [Awesome Vision-Language Navigation](https://github.com/daqingliu/awesome-vln)
- [Paper List and Resource Repository for Embodied AI](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List)
- [awesome-embodied-vla/va/vln](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)
- [Survey of Vision-and-Language Navigation](https://github.com/zhangyuejoslin/VLN-Survey-with-Foundation-Models)
- [Thinking-VLN](https://github.com/YicongHong/Thinking-VLN)
- [Awesome Vision-and-Language Navigation](https://github.com/eric-ai-lab/awesome-vision-language-navigation)
